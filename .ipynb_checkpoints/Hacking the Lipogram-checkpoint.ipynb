{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lipogram Investigation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, I knew [@Lipogrammatical](https://twitter.com/Lipogrammatical) was some kind of writing-based constraint, and the reference to [Anton Voyl](https://fr.wikipedia.org/wiki/La_Disparition_(roman%29) was a clue that the missing letter might be the most common in the English language, but could I prove it?\n",
    "<img src=\"perec.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the data\n",
    "My first thought was to pull stuff from Twitter's API, but they seem a little edgy about state-sponsored agents of chaos these days, and the API is more complex than what I was looking for. I came up with a hacky solution: using [a service](https://www.allmytweets.net/connect/) to pull the last 969 tweets (a month's worth, maybe?), and then copying the raw HTML into a text file. (It requires Twitter authentication, so I wasn't sure that `requests` would do the trick.) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('lipograms.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = soup.findAll('li')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "969"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace all images, URLs, and spans, which may contain misleading letters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in soup.findAll('a'):\n",
    "    a.replaceWithChildren()\n",
    "for a in soup.findAll('span'):\n",
    "    a.replaceWithChildren()\n",
    "for a in soup.findAll('img'):\n",
    "    a.replaceWithChildren()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = soup.findAll('li')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<li>How-To\n",
       " \n",
       " If you got hiv, say aids.  If you a girl,\n",
       " say you with child—nobody gonna stoop down\n",
       " to try and auscult a k… https://t.co/Whh4uzGFYv  Aug 02, 2018 </li>,\n",
       " <li>I RILLY DON'T CAIR DO U?  Jun 21, 2018 </li>,\n",
       " <li>Womp, womp.  Jun 20, 2018 </li>,\n",
       " <li>\"I can find a lot of formulations to say what I want, and, plus, do it with an assonantial music almost total, with… https://t.co/a96r3KtAJV  Jun 06, 2018 </li>,\n",
       " <li>Philip Roth's Human Stain: (Jim) Crow=Kafka (v. Faunia's amazing fantasia) just as Nathan is and is not Roth and Silk is and isn't too.  Jun 02, 2018 </li>]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove dates (Feb, Sep...), URLs within tweets (which were missed by Beautiful Soup), and line breaks and spaces just to make it look nice. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = [tweet.text for tweet in tweets]\n",
    "no_date = [tweet[:-13] for tweet in tweets]\n",
    "no_url = [re.sub('https?://t.co/\\w+ ', '', i) for i in no_date]\n",
    "no_new_line = [re.sub('\\n', ' ', i) for i in no_url]\n",
    "final = [re.sub(' +', ' ', i) for i in no_new_line]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined = ','.join(final).lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphabet = 'a b c d e f g h i j k l m n o p q r s t u v w x y z'.split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts=Counter(joined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "o 8493\n",
      "a 8084\n",
      "i 7892\n",
      "t 7149\n",
      "n 6307\n",
      "s 5408\n",
      "l 3875\n",
      "r 3695\n",
      "h 3400\n",
      "u 3044\n",
      "g 2818\n",
      "d 2721\n",
      "c 2463\n",
      "m 2380\n",
      "w 2248\n",
      "y 2141\n",
      "f 1804\n",
      "p 1749\n",
      "b 1453\n",
      "k 1060\n",
      "v 358\n",
      "j 356\n",
      "z 150\n",
      "x 133\n",
      "q 125\n",
      "e 76\n"
     ]
    }
   ],
   "source": [
    "for letter in sorted(counts, key=counts.get, reverse=True):\n",
    "    if letter in alphabet:\n",
    "        print (letter, counts[letter])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, we have very few e's, but still more than zero! How about that!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('joined.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(joined)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I created an e-dictionary, let's call it an `edict`: every tweet and its number of e's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "edict = {tweet:len(re.findall('e', tweet)) for tweet in final}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eek! Reemergence. events elsewhere ended, embers excepted. Yes: depressed.  23\n",
      "Well, this one is straightforward: attack was across the river from us, two blocks from the dojo we were looking at for J yesterday. #Sirens  11\n",
      "It was a dark and stormy night. At which point killing upon killing began. #HeyICanDoItToo H/T Scott Martin  2\n",
      "Paris January 4: Riparian SOBBING willows. 1.5 hour wait (we didn't) for MdL - gratuit aujourd'hui. To grim exposition sur la collaboration.  2\n",
      "Occupy MLA? I would but I'm lazy, & anyhow I got mine, Jack! Let adjuncts & junior faculty do it - I find it too much work. #omla @occupymla  2\n",
      ".@sravana Hilariously witty of you. I hadn't thought to peg 12 to 12. So no: this noonday son is - gasp! - what would be a military 4:00 pm.  2\n",
      "I got at last to what you’d call a croup or Boundary of that terrifying hollow, A bank of rocks which from a mounta…  1\n",
      "Dylan Thomas, bumped up a notch. Too long to avoid a photograph.  1\n",
      "\"Uncouth matutinal jocularity\"--S. Sassoon, \"Memoirs of a Fox-Hunting Man\" #LipogrammaticalQuotation (but singularizing originally pl. noun)  1\n",
      "Fancy lunch at usually way too much to pay Bistrot for L's May Day birthday (AND her Dad's a Marxist: it's all good) Not bad cost, actually.  1\n",
      "Day looking at windows and Gothic arch upon Gothic arch, not only metaphorically, at Our Lady, 96k SW of Paris. Adams right: amazing light.  1\n",
      "To town to which good news was brought, as Browning has it, to look at amazing 10-part world class work, by two 15th c bros. Back to Paris.  1\n",
      "Today mainly driving to AMS. Long. Traffic. Wrong coordination on map (β = warning no human pays attention to). Frustrating. But now in room  1\n",
      "Will it be sunny by 10:30? Watch this microblog, as I watch our cloudy sky.  1\n",
      "John Ford @ local film maison (1 of many!) with D: minor, truly good buddy film (2 guys riding on a mission) & tragedy. Sup w own buds. #Fix  1\n",
      "To school w D; fuss to get tix & lodging for my Mom's visit in April; Indian lunch in 10th; finish AMOK - good story; don't work much; Saul.  1\n",
      "7/II/2015 Saw Giotto's wall-painting of his Tuscan co-artist (in words) -- Giotto puts him in his own Paradiso. Same building: amazing David  1\n",
      "Today: painting show, lots of walking, supplying J. with stuff for school. Some writing; talk w/ my Mom. My Dad's possibly rallying but only  1\n",
      "Paris Jan. 25. My Dad is doing not bad and might push through this (for now). Anyhow today to Arts and Crafts hall. Astronomical instruments  1\n",
      "Paris, Jan. 9. Scary. Walking in tranquil parks (including stadium at which Paris would start) with clangor echoing from all compass points.  1\n",
      "Continuing: long walk to 9th to find foil training and practicing location for D. Good coach. D. starts tomorrow. Math and Master WS with J.  1\n",
      "@rosebyfarJust a day by day micro-(b)log. But it's Paris! Thus no call to say our day was good. That it was good is practically a tautology.  1\n",
      "Paris January 4: Riparian SOBBING willows. Didn't wait 1.5 hour for MdL: gratuit aujourd'hui. To grim exposition sur la collaboration. #Fix  1\n",
      "...Pynchon's latest: wazoo and cahoots. Pairing o’s is your only man.  1\n",
      "On muggy walk through an Audubon sanctuary, a complaining J says that it's similar to Nam though, okay, he admits, no VC.  1\n",
      "And while I'm at it, posting digits, I'll also say: Today is form 4868 day!  1\n",
      "I think my writing vocation (such as it is) can & will find only this 1 entry in my daybook, past, now & on its way: \"Visitor from Porlock.\"  1\n",
      "But I DID get through what you could call a bunch of Pynchon, so forth.  1\n",
      "I know I am not updating as much as I should. Not daily, as was my plan. But this is my 365th! I began in March, so that's a good ratio. #OG  1\n",
      "I just won't allow as to how Rajon Rondo could possibly be wrong. Rondo? Wrong? I think not.  1\n",
      "Hooray for the lipogrammatical victor! 1,461 additional days! #Obama2012. Forward!  1\n",
      "Glad that in Bloomington j-walking's normal. I am not coming off to my own mind as I too often do: an unwilling parody of law-abiding locals  1\n",
      "Reminding us of that notorious (and lipogrammatical) journalistic shout-out about film fashions: STICKS NIX HICK PIX.  1\n",
      "More Ryan lying: sub 3-hour marathon claim was a, um, fib, which Ryan \"took a lot of ribbing\" for. Good fun is all!  1\n",
      "Ack! Sciatica. Not as bad as it could be (knock wood) But how thoroughly annoying.  1\n",
      "DQ: \"I am always an optimist. But not in this world.\" (Kafka-Watt mash-up: \"But not for us.\" \"But not in this work.\") LipogrammaticalQuotes  1\n"
     ]
    }
   ],
   "source": [
    "for tweet in sorted(edict, key=edict.get, reverse=True):\n",
    "    if edict[tweet] != 0:\n",
    "        print (tweet, edict[tweet])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmm. It seems the rules are flexible..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (base)",
   "language": "python",
   "name": "regular"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
